# -*- coding: utf-8 -*-
"""importDatasetWithClustersToMongo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ci2xcRGs6wfRQ2HBdqSUnIgSKikfF1Hg
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install pyspark

import pickle as pk 

dfPickle = pk.load(open("/content/userRfmTable.pk","rb"))

from pyspark.sql import SparkSession
from pyspark.sql import functions as fn


spark = SparkSession.builder.master("local[*]").config("spark.mongodb.output.uri", "mongodb://demo:cQg0I3n39NcW6JpD@cluster0-shard-00-00-2fdob.gcp.mongodb.net:27017,cluster0-shard-00-01-2fdob.gcp.mongodb.net:27017,cluster0-shard-00-02-2fdob.gcp.mongodb.net:27017/test?ssl=true&replicaSet=Cluster0-shard-0&authSource=admin&retryWrites=true&w=majority").getOrCreate()
df = spark.read.csv("/content/drive/My Drive/Online Retail.csv",inferSchema=True,header=True)
dfUsersRFMclusters = spark.createDataFrame(dfPickle)
print(df.head())
dfUsersRFMclusters.head()

dfgrouped = df.groupBy("CustomerID","InvoiceNo").agg(fn.collect_set(fn.struct("StockCode","UnitPrice","Quantity","Description")).alias("stock"))#.show(truncate=False)
dfgrouped.show(truncate=False)
dfGoupedOrders = dfgrouped.groupBy("InvoiceNo").agg(fn.collect_set("stock").alias("orders"))#.show()
dfGoupedOrders.show(truncate=False)
dfgrouped = df.join(dfGoupedOrders,on="InvoiceNo")
dfgrouped.show(truncate=False)

dfgroup = dfgrouped.drop("StockCode","Description","Quantity","UnitPrice").drop_duplicates().filter("CustomerID is not null")
dfgroup.show(truncate=False)

parsedDataframe = dfgroup.groupBy("Country","CustomerID").agg(fn.collect_set(fn.struct("InvoiceNo","InvoiceDate","orders")).alias("invoices"))
parsedDataframe.show()
#parsedDataframe.write.format("mongo").mode("append").save()

parsedDataframe.printSchema()
userCollection = parsedDataframe.join(dfUsersRFMclusters,on="CustomerID")